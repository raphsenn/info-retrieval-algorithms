{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity search\n",
    "\n",
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    return re.findall(r\"[A-Za-z]+\", str(text).lower())\n",
    "\n",
    "def compute_vocabulary(file: str) -> dict[str, int]:\n",
    "    vocabulary: dict[str, int] = {}  \n",
    "    data = pd.read_csv(file)\n",
    "    i = 0\n",
    "    for _, row in data.iterrows():\n",
    "        title, overview, genre, crew = tokenize(row['title']), tokenize(row['overview']), tokenize(row['genre']), tokenize(row['crew'])\n",
    "        for token in title + overview:\n",
    "            if token not in vocabulary:\n",
    "                vocabulary[token] = i\n",
    "                i += 1\n",
    "            else: continue\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pirates', 'of', 'the', 'caribbean']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize('Pirates of the Caribbean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29632 unique words in movies.csv\n"
     ]
    }
   ],
   "source": [
    "vocab = compute_vocabulary('movies.csv')\n",
    "print(f\"{len(vocab)} unique words in movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class EmbeddingIndex:\n",
    "    def __init__(self, vocabulary: dict[str, int]) -> None:\n",
    "        self.word_embeddings_: dict[str, np.array] = {}\n",
    "        self.document_embeddings_ = None \n",
    "        self.vocabulary_: dict[str, int] = vocabulary\n",
    "        self.movie_titles_: list[str] = []\n",
    "\n",
    "    def build_from_file(self, file: str) -> None:\n",
    "        data = pd.read_csv(file) \n",
    "        docs_as_vec = [] \n",
    "        for _, row in data.iterrows():\n",
    "            title, overview, genre, crew = tokenize(row['title']), tokenize(row['overview']), tokenize(row['genre']), tokenize(row['crew'])\n",
    "            document_embedding = np.zeros(len(self.vocabulary_))\n",
    "            for word in title + overview:\n",
    "                document_embedding[self.vocabulary_[word]] += 1\n",
    "            docs_as_vec.append(document_embedding)\n",
    "            self.movie_titles_.append(row['title']) \n",
    "        self.document_embeddings_ = np.array(docs_as_vec)\n",
    "        \n",
    "        for word in self.vocabulary_:\n",
    "            word_embedding = np.zeros(len(self.vocabulary_))\n",
    "            word_embedding[self.vocabulary_[word]] = 1\n",
    "            self.word_embeddings_[word] = word_embedding\n",
    "\n",
    "    def cosine_similarity(self, x: np.array, y: np.array) -> float:\n",
    "        dot = np.dot(x, y)\n",
    "        xy_norm = norm(x) * norm(y)\n",
    "        return dot / xy_norm\n",
    "\n",
    "    def process_query(self, quyer: str):\n",
    "        query_words = tokenize(quyer)\n",
    "        query_vector = np.zeros(len(self.vocabulary_))\n",
    "        for word in query_words:\n",
    "            query_vector[self.vocabulary_[word]] += 1\n",
    "\n",
    "        similarities = list(self.cosine_similarity(self.document_embeddings_, query_vector))\n",
    "        similarities_sorted = list(sorted([(doc_id, sim) for doc_id, sim in enumerate(similarities)], key=lambda x: x[1], reverse=True))\n",
    "        return similarities_sorted\n",
    "\n",
    "    def generate_output(self, query: str, print_threshold: int = 10) -> None:\n",
    "        results = self.process_query(query)\n",
    "        print(f\"Query: {query}\") \n",
    "        for i, (doc_id, cos_sim) in enumerate(results):\n",
    "            cos_sim_to_percent = (cos_sim + 1) / 2\n",
    "            print(f\"Title: {self.movie_titles_[doc_id]}\\t Match: {cos_sim_to_percent}\")\n",
    "            if i > print_threshold:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchEngine = EmbeddingIndex(vocab)\n",
    "SearchEngine.build_from_file('movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: iron man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: iron man\n",
      "Title: Iron Man & Captain America: Heroes United\t Match: 0.5029070013099445\n",
      "Title: Iron Man & Hulk: Heroes United\t Match: 0.5021802509824583\n",
      "Title: Iron Man 2\t Match: 0.5014535006549723\n",
      "Title: Sex and Zen II\t Match: 0.5014535006549723\n",
      "Title: The Curious Case of Benjamin Button\t Match: 0.5014535006549723\n",
      "Title: Spider-Man: All Roads Lead to No Way Home\t Match: 0.5014535006549723\n",
      "Title: Iron Man: Rise of Technovore\t Match: 0.5014535006549723\n",
      "Title: TEKKEN: A Man Called X\t Match: 0.5014535006549723\n",
      "Title: Detective Conan: The Private Eyes' Requiem\t Match: 0.5014535006549723\n",
      "Title: Me Before You\t Match: 0.5010901254912292\n",
      "Title: Spider-Man 3\t Match: 0.5010901254912292\n",
      "Title: Ong Bak 2\t Match: 0.5010901254912292\n"
     ]
    }
   ],
   "source": [
    "SearchEngine.generate_output('iron man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: star wars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: star wars\n",
      "Title: Star Wars: The Clone Wars\t Match: 0.5021802509824583\n",
      "Title: Star Trek: The Captains' Summit\t Match: 0.5018168758187154\n",
      "Title: Empire of Dreams: The Story of the Star Wars Trilogy\t Match: 0.5014535006549723\n",
      "Title: LEGO Star Wars Holiday Special\t Match: 0.5014535006549723\n",
      "Title: Rogue One: A Star Wars Story\t Match: 0.5010901254912292\n",
      "Title: Doraemon: Nobita's New Great Adventure Into the Underworld - The Seven Magic Users\t Match: 0.5010901254912292\n",
      "Title: A Star Is Born\t Match: 0.5010901254912292\n",
      "Title: Phineas and Ferb: Star Wars\t Match: 0.5010901254912292\n",
      "Title: Doraemon: Nobita's Little Star Wars 2021\t Match: 0.5007267503274861\n",
      "Title: Star Wars\t Match: 0.5007267503274861\n",
      "Title: Star Wars: The Force Awakens\t Match: 0.5007267503274861\n",
      "Title: Star Wars: The Rise of Skywalker\t Match: 0.5007267503274861\n"
     ]
    }
   ],
   "source": [
    "SearchEngine.generate_output('star wars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: anime\n",
      "Title: Kimetsu Orchestra Concert\t Match: 0.5015416702543849\n",
      "Title: The Animatrix\t Match: 0.5010277801695899\n",
      "Title: Laid-Back Camp The Movie\t Match: 0.500513890084795\n",
      "Title: ODDTAXI in the Woods\t Match: 0.500513890084795\n",
      "Title: Dragon Ball: Yo! Son Goku and His Friends Return!!\t Match: 0.500513890084795\n",
      "Title: Death Note Relight 1: Visions of a God\t Match: 0.500513890084795\n",
      "Title: Halo Legends\t Match: 0.500513890084795\n",
      "Title: Naruto to Boruto: The Live 2019\t Match: 0.500513890084795\n",
      "Title: Evangelion: 1.0 You Are (Not) Alone\t Match: 0.500513890084795\n",
      "Title: Steins;Gate: The Movie - Load Region of Déjà Vu\t Match: 0.500513890084795\n",
      "Title: Phantom of the Kill: Zero's Rebellion\t Match: 0.500513890084795\n",
      "Title: Death Note Relight 2: L's Successors\t Match: 0.500513890084795\n"
     ]
    }
   ],
   "source": [
    "SearchEngine.generate_output('anime')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
