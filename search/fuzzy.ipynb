{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ED(x: str, y: str) -> int:\n",
    "    x, y = '$' + x, '$' + y\n",
    "    mat = np.zeros((len(x), len(y)), dtype=int)\n",
    "    for i in range(0, len(x)): mat[i][0] = i\n",
    "    for j in range(0, len(y)): mat[0][j] = j\n",
    "    for i in range(1, len(x)):\n",
    "        for j in range(1, len(y)):\n",
    "            if x[i] != y[j]:\n",
    "                mat[i][j] = min(mat[i-1][j], mat[i-1][j-1], mat[i][j-1]) + 1\n",
    "            else: \n",
    "                mat[i][j] = min(mat[i-1][j], mat[i-1][j-1], mat[i][j-1])\n",
    "    return mat[len(x)-1][len(y)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED(breiburg, freiburg) = 1\n",
      "ED(kid, kind) = 1\n",
      "ED(cat, wildcat) = 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"ED(breiburg, freiburg) = {ED('freiburg', 'breiburg')}\")\n",
    "print(f\"ED(kid, kind) = {ED('kid', 'kind')}\")\n",
    "print(f\"ED(cat, wildcat) = {ED('cat', 'wildcat')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PED(x: str, y: str, delta: int) -> int:\n",
    "    if len(x) + delta + 1 <= len(y):\n",
    "        x, y = '$' + x, '$' + y[:len(x) + delta]\n",
    "        mat = np.zeros((len(x), len(y)), dtype=int)\n",
    "        for i in range(0, len(x)): mat[i][0] = i\n",
    "        for j in range(0, len(y)): mat[0][j] = j\n",
    "        for i in range(1, len(x)):\n",
    "            for j in range(1, len(y)):\n",
    "                if x[i] != y[j]:\n",
    "                    mat[i][j] = min(mat[i-1][j], mat[i-1][j-1], mat[i][j-1]) + 1\n",
    "                else: \n",
    "                    mat[i][j] = min(mat[i-1][j], mat[i-1][j-1], mat[i][j-1])\n",
    "        return mat[len(x)-1][len(y)-1]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PED(Fibu, Freiburg) = 2\n",
      "PED(aff, baff) = -1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PED(Fibu, Freiburg) = {PED('Fibu', 'Freiburg', 2)}\")\n",
    "print(f\"PED(aff, baff) = {PED('aff', 'baff', 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_qgram(x: str, q: int, padding: int = 3) -> list[str]:\n",
    "    # Add padding to x. \n",
    "    x_padded = padding * '$' + x + padding * '$'\n",
    "    qgram = [x_padded[i:i+q] for i in range(0, len(x_padded)) if len(x_padded[i:i+q]) == q] \n",
    "    return qgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fre', 'rei', 'eib', 'ibu', 'bur', 'urg']\n",
      "['$$f', '$fr', 'fre', 'rei', 'eib', 'ibu', 'bur', 'urg', 'rg$', 'g$$']\n"
     ]
    }
   ],
   "source": [
    "print(compute_qgram('freiburg', q=3, padding=0))\n",
    "print(compute_qgram('freiburg', q=3, padding=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar words have many q-grams in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fr', 're', 'ee', 'eb', 'bu', 'ur', 'rg', 'ge', 'er']\n",
      "['br', 're', 'ee', 'eb', 'bu', 'ur', 'rg', 'ge', 'er']\n"
     ]
    }
   ],
   "source": [
    "print(compute_qgram('freeburger', q=2, padding=0))\n",
    "print(compute_qgram('breeburger', q=2, padding=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(list1: list, list2: list) -> list:\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    return list(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bu', 'ur', 'rg', 'ee', 're', 'ge', 'eb', 'er']\n"
     ]
    }
   ],
   "source": [
    "qgram1 = compute_qgram('freeburger', q=2, padding=0)\n",
    "qgram2 = compute_qgram('breeburger', q=2, padding=0)\n",
    "inter = intersect(qgram1, qgram2)\n",
    "print(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (2, 1), (3, 3), (5, 1), (9, 2)]\n",
      "[(1, 2), (3, 1), (5, 1)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def merge_lists(list1: list, list2: list) -> list:\n",
    "    i, j, n, m = 0, 0, len(list1), len(list2)\n",
    "    merged = []\n",
    "    while i < n and j < m:\n",
    "        if list1[i][0] < list2[j][0]: merged.append(list1[i]); i+=1\n",
    "        elif list1[i][0] > list2[j][0]: merged.append(list2[j]); j+=1\n",
    "        else:\n",
    "            new_score = list1[i][1] + list2[j][1]\n",
    "            merged.append((list1[i][0], new_score))\n",
    "            i += 1\n",
    "            j += 1\n",
    "    for x in list1[i:]: merged.append(x)\n",
    "    for y in list2[j:]: merged.append(y)\n",
    "    return merged\n",
    "print(merge_lists([(1, 2), (3, 1), (5, 1)], [(2, 1), (3, 2), (9, 2)]))\n",
    "print(merge_lists([(1, 2), (3, 1), (5, 1)], []))\n",
    "print(merge_lists([], []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class FuzzySearch:\n",
    "\n",
    "    def __init__(self, q: int, delta: int=1) -> None:\n",
    "        # Map qgrams to (doc_id, tf-score)\n",
    "        # tf-score = number of times word occurs in document.\n",
    "        self.inverted_lists: dict[str, list[tuple[int, int]]] = {}\n",
    "\n",
    "        # Save city names\n",
    "        self.city_names: list[str] = []\n",
    "        self.city_population: list[int] = []\n",
    "\n",
    "        self.city_norm_names: list[str] = []\n",
    "\n",
    "        self.q = q\n",
    "        self.padding = q - 1\n",
    "        self.delta = delta\n",
    "\n",
    "    def tokenize(self, text: str) -> list[str]:\n",
    "        WORD_PATTERN = '[a-zA-Z]+'\n",
    "        return re.findall(WORD_PATTERN, str(text).lower())\n",
    "\n",
    "    def norm(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def build_from_file(self, file: str) -> None:\n",
    "        cities = pd.read_csv(file)\n",
    "        doc_id: int = 1 \n",
    "        for _, row in cities.iterrows():\n",
    "            for word in self.tokenize(row['name']):\n",
    "                for qgram in compute_qgram(word, self.q, self.padding):\n",
    "                    if qgram not in self.inverted_lists:\n",
    "                        self.inverted_lists[qgram] = [(doc_id, 1)]\n",
    "                    else:\n",
    "                        if self.inverted_lists[qgram][-1][0] == doc_id:\n",
    "                            new_tf = self.inverted_lists[qgram][-1][1] + 1\n",
    "                            self.inverted_lists[qgram].append((doc_id, new_tf))\n",
    "                        else:\n",
    "                            self.inverted_lists[qgram].append((doc_id, 1))\n",
    "            self.city_names.append(row['name'])\n",
    "            self.city_norm_names.append(self.norm(row['name']))\n",
    "            self.city_population.append(row['population']) \n",
    "            doc_id += 1\n",
    "\n",
    "    def intersect(self, qgram1: list[str], qgram2: list[str]) -> list[str]:\n",
    "        qset1 = set(qgram1)\n",
    "        qset2 = set(qgram2)\n",
    "        inter = list(qset1.intersection(qset2))\n",
    "        return inter\n",
    "    \n",
    "    def process_query(self, query: str):\n",
    "        query = self.norm(query) \n",
    "        query_gram = compute_qgram(query, self.q, self.padding)\n",
    "        \n",
    "        lists = []\n",
    "        for qgram in query_gram:\n",
    "            if qgram in self.inverted_lists: \n",
    "                intersect = [pair for pair in self.inverted_lists[qgram]]\n",
    "                lists.append(intersect) \n",
    "        \n",
    "        merged = []\n",
    "        for x in lists:\n",
    "            merged = merge_lists(merged, x)\n",
    "        \n",
    "        matches = []\n",
    "        for doc_id, tf in merged:\n",
    "            ped = PED(query, self.city_norm_names[doc_id-1], self.delta)\n",
    "            if 0 < ped <= self.delta:\n",
    "                matches.append((doc_id, ped))\n",
    "        return matches\n",
    "\n",
    "    def generate_output(self, query, threshold: int = 10):\n",
    "        results = self.process_query(query)\n",
    "        print(f'Query: {query}') \n",
    "        for i, (doc_id, ped) in enumerate(results):\n",
    "            print(self.city_names[doc_id-1])\n",
    "            if i > threshold:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Frei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Frei\n",
      "Freie Hansestadt Bremen\n",
      "Freie Hansestadt Bremen\n",
      "Freiburg im Breisgau\n",
      "Freiburg im Breisgau\n",
      "Freising\n",
      "Freiberg\n",
      "Freital\n",
      "Freilassing\n",
      "Freiberg am Neckar\n",
      "Pfreimd\n",
      "Freinsheim\n",
      "Freinsheim\n"
     ]
    }
   ],
   "source": [
    "SearchEngine = FuzzySearch(q=2, delta=1)\n",
    "SearchEngine.build_from_file('german_cities.csv')\n",
    "SearchEngine.generate_output('Frei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Be\n",
      "Berlin\n",
      "Bremen\n",
      "Bielefeld\n",
      "Oberhausen\n",
      "Bremerhaven\n",
      "Bergisch Gladbach\n",
      "Bergheim\n",
      "Bergkamen\n",
      "Oberursel (Taunus)\n",
      "Bietigheim-Bissingen\n",
      "Bietigheim-Bissingen\n",
      "Bernau bei Berlin\n"
     ]
    }
   ],
   "source": [
    "SearchEngine.generate_output('Be')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
